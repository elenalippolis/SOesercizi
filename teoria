1. La libreria C fornisce delle funzioni che consentono di richiedere system call (per esempio open, read, ecc.). 
Come sono realizzate queste funzioni? Come vengono passati i parametri e il valore di ritorno delle system call?

La libreria C standard fornisce delle funzioni che facilitano l'uso di system call come 'open', 'read', ecc.
Queste funzioni sono in genere implementate come wrapper intorno alle system call del sistema operativo sottostante.
Una system call non è gestita da una libreria, ma dal kernel del s.o.. 
Quando un programma fa una system call, fa un'interruzione del sw che sposta l'esecuzione nel kernel.
Questo è necessario perché le system call richiedono privilegi più elevati di quelli che i normali programmi utente hanno.

Quando viene eseguita una system call, i parametri vengono passati solitamente attraverso registri della CPU (es. registri ecx)
Dopo che i parametri sono stati caricati nei registri, il programma esegue un interruzione del software, che sposta l'esecuzione nel kernel-
Il kernel guarda il numero della system call nel registro appropriato e esegue la funzione appropriata-
Dopo che la system call è stata eseguita, il valore di ritorno viene caricato in un registro. L'esecuzione viene restituita al programma utente,
che può controllare il valore nel registro per vedere il risultato della system call.

Le funzioni di sistema in C sono implementate come funzioni di libreria che forniscono un'interfaccia di alto livello alle system call del s.o.
es.
int open(const char *pathname, int flags) {
    return syscall(SYS_open, pathname, flags);
}
è una funzione di basso livello

2. Dati 4 dischi da 1GB, si possono memorizzare più dati usando una organizzazione RAID10 RAID5? perché?
- RAID10 (noto come RAID 1+0): configurazione che è un mix di RAID1 e RAID0.
In RAID1 i dati vengono scritti in modo identico su due dischi (mirroring), offrendo alta ridondanza.
In RAID0, i dati vengono suddivisi (striped) tra i dischi, senza ridondanza.
In RAID10, i dati vengono prima replicati (RAID1) e poi questi set di dati replicati vengono suddivisi tra i dischi (RAID0).
Se hai 4 dischi da 1GB ciascuno, in RAID10  si avrebbe solo 2GB di spazio di archiviazione utilizzabile perché i dati vengono
replicati tra i dischi.
-RAID 5 (striping con parità): in RAID5 i dati vengono suddivisi e scritti su tutti i dischi, come in RAID0. 
Viene anche calcolata l'informazione di parità per ogni blocco di dati e viene scritta su uno dei dischi. Questa informazione di parità
consente la ricostruzione dei dati se un disco fallisce.
Se hai 4 dischi da 1 GB ciascuno, aversti 3GB di spazio, perché l'equivalente di un disco intero viene usato per l'informazione di parità.
RAID5 memorizza 3 dischi, RAID10 solo 2. Quindi RAID5 dà più spazio rispetto a RAID10.

3. Dimostrare che se un algoritmo di rimpiazzamento è a stack allora non può soffrire dell'anomalia di Belady.

L'anomalia di Belady è un fenomeno in cui l'aumento della quantità di risorse di memoria fisica (es. numero di page frame)
può portare a un aumento del numero di page fault in un algoritmo di rimpiazzamento delle pagine. Questa anomalia è particolarmente
evidente nell'algoritmo FIFO (First-in, first-out) per la sostituzione delle pagine.
Un algoritmo di rimpiazzamento è detto a stack quando l'ordine delle pagine nel working set (le pagine attualmente caricate in memoria)
mantiene la proprietà LIFO, come uno stack.
Gli algoritmi a stack, come LRU, hanno la proprietà che un aumento del numero di page frame non può mai aumentare il numero di page fault.
Quindi non soffrono dell'anomalia di Belady.
La ragione di ciò è che, se un algoritmo di rimpiazzamento segue la proprietà di stack, allora l'insieme delle pagine in memoria con N page
frame è sempre un sottoinsieme dell'insieme delle pagine in memoria con N+1 page frame. In altre parole, se aggiungi più memoria, 
le pagine che erano in memoria prima ci saranno ancora, più qualche altra pagina.
Di conseguenza, non puoi avere più page fault.

4. L'algoritmo del Banchiere evita che si verifichino situazioni di deadlock. Sembra una funzione desiderabile,
eppure viene raramente usato nei sistemi reali, perché?

L'algoritmo del banchiere è un metodo di deadlock prevention. Anche se può prevenire deadlock, non viene spesso usato nei sistemi reali perché:
- conoscenza completa richiesta: richiede una conoscenza completa e precisa delle risorse  future che ciascun processo richiederà.
Questo è raramente possibile nei sistemi operativi reali, dove le richieste di risorse possono essere dinamiche e imprevedibili.
- overhead computazionale: richiede un'analisi costante e dettagliata dello stato delle risorse e di tutti i processi. QUesto può postare a un overhead
computazionale
- riduzione dell'uso delle risorse: tende ad essere conservativo nell'allocazione delle risorse per prevenire i deadlock. Questo può portare a un
sotto utilizzo delle risorse, riducendo l'efficienze complessiva
- è complesso da implementare

Non so se la risposta sia giusta.

I processi danno a priori la quantità massima di risorse da utilizzare.

5. quali operazioni compie un device driver per iniziare un'operazione di I/O? 
Come viene rilevato il completamento dell'operazione di I/O?

Un device driver, o driver di dispositivo, è un componente software che permette al s.o. di interagire con un dispositivo
hw. Quando un'applicazione o il s.o. desidera iniziare un'operazione di I/O con un dispositivo, il device driver svolge un
insieme di operazioni:
- interpretazione della richiesta: il s.o. invia una richiesta di I/O al driver di dispositivo. QUesta potrebbe essere per esempio
la lettura o la scrittura di dati su disco. Il driver interpreta la richiesta in termini di comandi specifici per il dispositivo
- preparazione del dispositivo: il driver potrebbe dover preparare il dispositivo per l'operazione
- invio del comando al dispositivo: una volta che il dispositivo è pronto, il driver invia il comando al dispositivo. Questo potrebbe 
comportare la scrittura di valori specifici in particolari indirizzi di memoria mappati sul dispositivo, o l'emissione di un segnale al dispositivo.
Per rilevare il completamento dell'operazione di I/O, esistono 2 principali approcci:
- polling: il driver di dispositivo continua a controllare lo stato del dispositivo per vedere se ha completato l'operazione. Questo può essere
inefficiente in termini di utilizzo della CPU.
- interrput: approccio più efficiente. Quando l'operazione di I/O è completata, il dispositivo emette un segnale di interrput alla CPU.
Questo segnale fa sì che la CPU interrompa quello che sta facendo e passi il controllo a una routine di servizio di interrupt, che può
essere parte del driver di dispositivo. QUesta routine gestisce il completamento dell'operazione di I/O, es. leggendo i dati dal dispositivo e 
copiandoli in memoria, e poi segnalando al sistema operativo che l'operazione è stata completata.

6. In un sistema a memoria virtuale un interrupt di tipo TLB-miss indica sempre la mancanza di una pagina
in memoria (page miss)?

No, un interrupt di tipo TLB-miss non indica necessariamente la mancanza di una pagina in memoria (page miss).
Il TLB (translation lookaside buffer) è una piccola cache hardware che contiene una parte della tabella di traduzione delle pagine.
Quando un processo tenta di accedere a un indirizzo di memoria, il sistema prima controlla il TLB per vedere se la traduzione dall'indirizzo virtuale
all'indirizzo fisico è gia disponibile. Se c'è (TLB hit), la CPU può accedere rapidamente all'indirizzo fisico corrispondente. Se non c'è (TLB miss)
il sistema deve cercare la traduzione nella tabella delle pagine (processo più lento).

Un page miss si verifica quando un processo tenta di accedere a una pagina che non è attualmente caricata in memoria fisica. Questo è noto anche come page fault.

Quindi un TLB miss significa solo che la CPU deve caricare la traduzione dell'indirizzo nella tabella delle pagine, non che la pagina non sia in memoria.
Se la pagina è inn memoria, ma la sua traduzione non è nel TLB, si avrà un TLB miss seguito da un accesso alla tabella delle pagine, ma non un page fault.
Se la pagina non è in memoria, avremo un TLB miss seguito da un page fault.

7. Quali sono le metodologie che si possono utilizzare per minimizzare i rischi di attacco tramite worm?
I worm sono una tipologia di malware che può diffondersi autonomamente da un sistema all'altro, sfruttando varie vulnerabilità del sw.
Misure da adottare per minimizzare il rischio di attacco tramite worm:
- aggiornamenti sw: spesso gli aggiornamenti includono patch di sicurezza che risolvono vulnerabilità note che i worm potrebbero sfruttare
- firewall: può aiutare a bloccare le connessioni non autorizzate al sistema, che un worm potrebbbe cercare di stabilire

8. confrontare l'allocazione concatenata e l'allocazione indicizzata nei file system. Quali sono i pro e 
i contro dei due metodi?

- allocazione concatenata: in un sistema di allocazione concatenata, ogni file è una lista concatenata di blocchi di disco. Ogni blocco contiene 
un puntatore al blocco successivo del file.
pro: 
    - semplice: l'allocazione concatenata è semplice da implementare e gestire. non richiede complesse strutture dati per tener traccia dei blocchi di un file
    - efficiente nello spazio: non richiede spazio aggiuntivo per memorizzare indici dei blocchi
contro:
    - accesso sequenziale: supporta solo l'accesso sequenziale ai file. Se si vuole accedere a un blocco specifico di un file, è necessario scorrere tutta la lista
      dei blocchi dal primo fino al blocco desiderato (molto lento)
    - affidabile: se un puntatore viene corrotto, si può perdere l'accesso al resto del file.

- allocazione indicizzata: c'è un blocco di indice per ogni file, che contiene puntatori a tutti gli altri blocchi del file
pro:
    - accesso diretto: permette accesso diretto a qualsiasi blocco di un file, ciò rende più veloce l'accesso a un singolo blocco di un file grande
    - flessibile: i file possono essere facilmente estesi aggiungendo nuovi blocchi e aggiornando l'indice
contro:
    - overhead di spazio: ogni file ha bisogno di un blocco indice, che può richiedere una significativa quantità di spazio disco se ci sono molti file piccoli
    - complesso: più complesso da implementare rispetto all'allocazione concatenata. Richiede la gestione di strutture dati più complesse
    - ricerca: la ricerca di un file può richiedere tempo, in quanto bisogna prima leggere l'indice e poi accedere al blocco dati

risposta breve:  l'allocazione indicizzata è generalmente più flessibile e permette un accesso più rapido ai dati, ma a costi di spazio e complessità superiori. 
L'allocazione concatenata è più semplice e richiede meno spazio, ma è meno flessibile e più lenta per l'accesso ai dati. 

9. Quali sono gli interrupt hardware più frequenti e quali le trap (interrupt software) più frequenti?

Gli interrupt sono meccanismi usati nei s.o. per interrompere temporaneamente l'esecuzione normale del processo e passare il controllo a una routine
di servizio specifica. 
Esempi di interrupt hw:
- interrupt di I/O: interrupt generati da dispositivi hardware (tastiera, mouse, stampante,..) quando hanno bisogno di attenzione del s.o.
- interrupt di timer: generati da timer hw a intervalli regolari. Usati per implementare funzioni come la preemption in un sistema multitasking
- interrupt di errore hw: generati quando si verifica un errore hw (errore di parità di memoria, errore di I/O su disco)

Esempi di trap (sw):
- system call: sono richieste fatte da un processo al s.o. per eseguire un'azione specifica (lettura o scrittura di file, apertura o chiusura socket, ..)
- eccezioni: come la divisione per 0 o l'accesso a un'area di memoria non autorizzata, generano una trap che interrompe l'esecuzione del processo e passa il controllo
a una routine di gestione delle eccezioni
- segnali: in alcuni s.o. i segnali sono un tipo di trap sw che può essere usato per interrompere un processo o indormarlo di un evento


10. A cosa serve il Translation Lookahead Buffer?

Il TLB è una componente hw presente nell'unità di gestione della memoria (MMU). Il suo scopo è migliorare l'efficienza della traduzione degli indirizzi di memoria
virtuali in indirizzi fisici.
Nei sistemi con memoria virtuale, ogni processo ha il proprio spazio di indirizzamento virtuale, che viene mappato nello spazio di indirizzamento fisico del computer.
Questa mappatura avviene in "pagine". 
Le informazioni sulla mappatura da indirizzi virtuali a fisici sono conservate nella tabella delle pagine.
Ogni volta che un processo tenta di accedere a un indirizzo di memoria, la CPU deve tradurre quell'indirizzo virtuale in uno fisico.
Questo comporta la ricerca nella tabella delle pagine (operazione anche lenta, soprattutto se è grande e conservata nella memoria principale).

Il TLB è una piccola cache che conserva le traduzioni recenti di indirizzi virtuali in indirizzi fisici. Quando la CPU deve tradurre un indirizzo, prima controlla il TLB, 
se la traduzione c'è (TLB hit), la CPU può usare quell'indirizzo fisico, sennò (TLB miss), la CPU deve cercare la traduzione nella tabella delle pagine.

11. Quali problemi può porre l'implementazione di un Sistema Operativo con il supporto di memoria virtuale e di
controller di I/O di tipo DMA (direct memory access)?

- incoerenza dei dati: quando si usa il DMA, un dispositivo di I/O può leggere o scrivere direttamente dalla o nella memoria senza l'intervento del processore.
Se il sistema operativo usa la memoria virtuale, gli indirizzi fisici usati dal DMA potrebbero non corrispondere a quelli virtuali usati dal processo.
Questo può causare problemi se un processo modifica i dati in un indirizzo virtuale mentre un dispositivo DMA sta leggendo o scrivendo dal corrispondente indirizzo fisico.
- sostituzione di pagine: il s.o. può decidere di spostare le pagine di memoria tra la memoria principale e lo storage di massa (swapping o paging) per fare spazio a nuovi dati.
Se una pagina viene spostata mentre è in corso un'operazione di DMA, i dati potrebbero finire nel posto sbagliato o essere persi.
- TLB miss: se un controller DMA usa indirizzi fisici per il trasferimento dei dati e la corrispondente pagina non è presente in memoria (TLB miss), il s.o. deve essere in grado di gestire
tale situazione, assicurandosi che le pagine coinvolte nelle operazioni DMA siano bloccate in memoria oer tutta la durata dell'operazione.

da controllare

12. Qual è la complessità computazionale dell'algoritmo del banchiere monovaluta e quella del banchiere multivaluta?
L'algoritmo del banchiere è un metodo usato nei s.o. per prevenire il deadlock.
- algoritmo del banchiere monovaluta: l'operazione chiave è la ricerca di una sequenza sicura di processi. Questo richiede che per ogni processo nel sistema l'algoritmo
verifichi se le risorse richieste sono inferiori alle risorse disponibili. Nel caso peggiore, questo fovrebbe essere fatto per ogni possibile ordine dei processi, quindi
O(n^2), dove n è il numero dei processi
- algoritmo del banchiere multivaluta: la complessità aumenta a causa della necessità di gestire più tipi di risorse. Ogni richiesta di risorse deve specificare il tipo e la quantità
di risorse richieste, e l'algoritmo deve verificare se quelle risorse sono disponibili.
O(n*m^2), dove n è il numero di processi e m è il numero di tipi di risorse.

13. Perché il compilatore C è scritto in C? Come si fa a compilare il compilatore C se per compilarlo occorre il compilatore
C?

La scelta di scrivere il compilatore C in C stesso si basa sulla pratica di "bootstrap" (o auto compilazione). Offre vantaggi, tra cui la possibilità di usare le funzionalità di C per migliorare
e ottimizzare il compilatore stesso, la facilità di manutenzione e l'efficienza.
Funziona così:
- compilazione iniziale: la prima versione del compilatore C è scritta in un linguaggio diverso (assembly o altro). Questo primo compilatore C viene usato per compilare il codice sorgente C
in un eseguibile.
- bootastrap: una volta che il primo compilatore C è stato creato, può essere usato per compilare versioni successive del compilatore C scritte in C stesso.
Questo processo può essere ripetuto all'infinito, con ogni nuova versione del compilatore che viene compilata usando la versione precedente.

14. Come si calcola la lunghezza massima di un file in un file system di tipo UNIX?

La lunghezza massima di un file in un file system UNIX può dipendere da vari fattori (es. il tipo di file system in uso, come ext4), la dimensione del blocco di memoria ( e le limitazioni del s.o.)
In generale la dimensione massima di un file in un file system UNIX è determinata dalla massima quantità di blocchi di memoria che un file può indirizzare.

Ad esempio, nel file system ext4 i puntatori ai blocchi di memoria sono di 4 byte (32 bit), e la dimensione predefinita del blocco è di 4KiB (4096 byte).
Questo significa che la dimensione massime del file sarebbe di 4byte*2^32 (16TiB)
ext4 supporta anche la dimensione del blocco dino a 64 KiB, con dimensione massima del file di 256 TiB.

controllare

15. Fornire un elenco di incongruenze che possono venir rilevate dal fsck (file system check) applicato a file
system di tipo UNIX (e.g. ext2, bffs). Per ogni tipo di incongruenza indicare come viene riscontrata e con quali
operazioni il fsck può ripristinare la coerenza.

Il comando fsck (file system check) è un'utility di sistema usata su s.o. UNIX per controllare e riparare incongruenze nei file system.
Alcune incongruenze che fsck può rilevare in file system come ext2 o ext4:
- incongruenze nei contatori di riferimento (link count): il contatore di riferimento di un file o directory è il numero di riferimento (o link) a quel file o directory.
Se fsck scopre che il contatore di riferimento è incongruente con il numero effettivo di riferimenti, correggerà il contatore di riferimento col numero corretto.
- blocchi di dati "orfani": sono blocchi di dati che non sono riferiti da nessun inode.  Fsck li identifica e li libera, riportandoli nella lista dei blocchi liberi
- inode non utilizzati: sono inode che contengono dati ma non sono riferiti a nessun file o directory. Fsck li identifica e li libera, riportandoli nella lista degli
inode liberi
- blocchi di dati doppiamente riferiti: sono blocchi di dati che sono riferiti da più di un inode. Fsck li identifica e può creare una nuova copia del blocco 
per ciascuno dei file che lo riferiscono, assicurando che ogni file abbia il proprio blocco dati univoco.
- directory cicliche: sono directory che contengono riferimenti a se stesse, creando un ciclo infinito. Fsck li identifica e rimuove i riferimenti ciclici
- blocchi di dati fuori limite: sono blocchi dati che hanno indirizzi fuori dai limiti validi del file system (overflow). Fsck li identifica e
li rimuove dall'inode che li riferisce, e li riporta nella lista dei blocchi liberi.
- file system unmounted scorrettamente

16. Perché un algoritmo di rimpiazzamento a stack non può essere soggetto ad anomalia di Belady?

L'anomalia di Belady è una situazione in cui l'aumento della quantità di memoria disponibile per il paging può in realtà aumentare il numero di page fault, invece di ridurlo.
Gli algoritmi di rimpiazzamento a stack non possono subire l'anomalia di Belady. Questo è dovuto al loro comportamento intrinseco: se un algoritmo di rimpiazzamento di pagine
può essere implementato in modo che l'insieme di pagine in memoria per un numero n di frame di pagina sia sempre un sottoinsieme dell'insieme di pagine in memoria per n+1 frame di pagina, 
allora quell'algoritmo è immune all'anomalia di Belady.

17. Le password (criptate) nei sistemi UNIX moderni sono memorizzate in un file inaccessibile agli utenti (/etc/shadow).
Perché?

La ragione principale per cui i sistemi UNIX moderni memorizzano le password criptate in un file separato inaccessibile agli utenti  (/etc/shadow)
è per migliorare la sicurezza.
Nei primi sistemi UNIX le password criptate erano memorizzate nel file /etc/passwd, che è leggibile da tutti gli utenti. QUesto file conteneva anche altre informazioni importanti sugli account utente,
quindi doveva essere accessibile a tutti per consentire funzioni come l'elenco degli utenti.
Avere le password criptate in un file leggibile a tutti ha rischi di sicurezza. Anche se la password erano criptate, un attaccante potrebbe sempre prenderle e usare tecniche come attacco forza bruta per cercare
di decifrarle. 
Le password sono quindi ora memorizzate in un file separato /etc/shadow, che può essere letto solo dall'utente root.

18. Nello scheduler di tipo Shortest Remaining TIme First (versione preemptive di STF: Shortest time first), il tempo
residuo può diventare negativo. Perché?

19. Quando si usano i dischi a stato solido i file system vengono configurati in modo da non aggiornare il tempo di
ultimo accesso ai file (noatime). Perché?

20. Perché può essere difficoltoso revocare le capability di accesso a risorse?

21. Qual è la differenza fra una funzione di libreria (e.g. sprintf) e una system call (e.g. write).

22. Come si calcola la lunghezza massima di un file in un FIle System tipo UNIX (bffs, ext2, minix ecc)?

23. Come si fa a risolvere una situazione di deadlock?

24. Perché è meglio la paginazione della compattazione di memoria?

25. Per implementare un servizio di autorizzazione di tipo capability è meglio usare crittografia simmetrica o crittografia
a chiave pubblica? perché? E' necessario usare un metodo specifico (crittografia simmetrica o crittografia a chiave
pubblica) o il servizio di autorizzazione potrebbe essere implementato con entrambi?

26. Perché viene usata la paginazione per implementare la memoria virtuale?

27. L'algoritmo del banchiere dato uno stato di allocazione delle risorse restituisce un valore binario: safe o non safe.
In quali casi il sistema operativo esegue l'algoritmo del banchiere? Cosa succede se il risultato è safe e cosa se il
risultato è non-safe?

28 Fornire esempi di file system con allocazione contigua, e spiegare perché sarebbe inefficiente usare altri metodi di
allocazione nei casi d'uso tipici di questi file system.

29. perché l'invenzione degli interrupt ha reso i sistemi operativi più efficienti?

30. Usando l'algoritmo di rimpiazzamento FIFO la stringa di riferimenti 1,2,3,4,1,2,5,1,2,3,4,5 genera più page
fault con una memoria di 4 frame di quanti ne vengano generati con una memoria di 3 frame (anomalia di Belady)
i) si generi una stringa di riferimenti che generi più page fault in una memoria di 5 frame rispetto ad una da 4 frame.
ii) si costruisca una regola generale per costruire stringhe di riferimenti che generino più page fault in una memoria di
n frame rispetto a quelli generati in una memoria da n - 1 frame 

31. Lo scheduler sceglie fra i processi ready quale porre in esecuzione. Ma cosa succede quando la coda dei processi
ready è vuota?

32. Quali vantaggi offre RAID5 rispetto a RAID1?

33. Se per effetto di un guasto o di un bug il numero di hard link di un i-node è errato, quali conseguenze possono
esserci?

34. Quali eventi causano la valutazione dell'algoritmo del banchiere? Cosa si fa se lo stato risulta unsafe e cosa invece se
è safe?

35. Perché il nome del file non è memorizzato all'interno dell'i-node nei file system tipo UNIX (e.g. ext2/3/4)?

36 Un bug di tipo buffer overflow consente ad un attaccante di spedire più dati di quelli che il buffer di ricezione può
contenere, tracimando così nelle aree di memoria di altre variabili. Come è stato possibile in tanti casi che venisse
spedito codice macchina e che il programma vittima dell'attacco lo eseguisse?

37 come fa l'allocazione gerarchica ad evitare che si possano verificare casi di deadlock?

38. Per rendere uno scheduler round-robin più pronto a servire i processi interattivi si decide di dimezzare la durata del
time slice. Quali effetti collaterali può avere la scelta?

39. perché DMA viene utilizzato per le unità di memoria secondaria (es dischi) e non per terminali?

40. cosa succede in un sistema operativo quando un processo utente tenta di eseguire una operazione
illegale (es. divisione per zero)? Lo standard POSIX (UNIX) cosa prevede in questo caso?

41.L'algoritmo di rimpiazzamento second chance (detto anche dell'orologio) è a stack? Perché viene
preferito a LRU?

42. Quali sono le caratteristiche negative dell'uso delle Access Control List per la memorizzazione delle
informazioni di autorizzazione

43.  perché una situazione di trashing si può risolvere sospendendo l'esecuzione di processi?

44. come fa il sistema operativo a sospendere i processi che sono in attesa del completamento di una
richiesta di I/O?

45. quale tipo di crittografia è necessaria per implementare un servizio di autorizzazione basato su
capability? perché? (NB la domanda non fa riferimento alle POSIX capability)

46. Perché con due dischi si preferisce usare RAID1 piuttosto che RAID5? (infatti RAID5 è definito con un
minimo di 3 dischi).

47. In un sistema ci sono 3 classi di risorse A, B, C e 4 processi p,q,r,s.
In un determinato istante le tre risorse della classe A sono assegnate a p (due risorse) e a s (1 risorsa), l'unica risorsa
della classe B è assegnata ad r mentre le due risorse della classe C sono assegnate a q ed a r. Sono pendenti le
seguenti richieste: p ed s richiedono una risorsa della classe C e q chiede una risorsa della classe A.
Lo stato così determinato è di deadock? Mostrare il procedimento usato per ottenere la risposta.

48.  perché uno scheduler round-robin può essere inadatto a gestire processi con I/O multimediale?

49. per risolvere un problema di trashing è necessario terminare forzatamente dei processi o è sufficiente bloccare
l'esecuzione di qualche processo e riattivarli successivamente? Perché?
50.  Con lo stesso numero di dischi, RAID1 o RAID5 consente di memorizzare più dati? Perché? Quale è più sicuro?
Perché?

51. Perché è difficile revocare una autorizzazione fornita tramite una capability?

52. perché uno scheduler round-robin può essere inadatto a gestire processi con I/O multimediale?
Uno scheduler round-robin inserisce un processo in attesa di una risorsa IO
in fondo alla coda dei processi ready una volta che esso viene sbloccato,
al fine di dare la possibilita' ad altri processi in attesa di compiere le
proprie azioni e per evitare starvation. Tuttavia, cosi' facendo, un processo
che esegue un alto numero di richieste IO come una applicazione multimediale,
potrebbe trovarsi troppo tempo in coda ad attendere l'esecuzioen di altri
processi (in particolare cio' si verifica in un sistema "affollato").

Una possibile soluzione a questa problematica e' inserire le applicazioni
con un alto numero di operazioni IO in una cosa di priorita' piu' alta per
dargli precedenza rispetto ad altre task che possono aspettare come demoni
in background o task ricorrenti (cronjob).

53.  per risolvere un problema di trashing è necessario terminare forzatamente dei processi o è sufficiente bloccare
l'esecuzione di qualche processo e riattivarli successivamente? Perché?
Per risolvere il trashing non e' _necessario_ uccidere forzatamente alcun
processo. Sicuramente l'eliminazione di un processo e la conseguente
liberazione di una determinata area di memoria risulterebbe in una veloce
soluzione al problema veloce.
Tuttavia, per uscire da una situazione di trashing, che si verifica qunado
molti processi accedeono ad indirizzi logici frequentemenete sparsi tra
memoria centrale e secondaria (generando innumerevoli page fault), e'
sufficiente mettere in pausa alcuni processi, in attesa che altri completino
la loro esecuzione e liberino aree di memoria dove i processi messi in pausa
potranno poi caricare i dati a loro necessari in memoria centrale.

54. Con lo stesso numero di dischi, RAID1 o RAID5 consente di memorizzare più dati? Perché? Quale è più sicuro?
Perché?
A partia' di dirschi RAID 5 consente di utilizzare una maggior quantita' di
spazio per memorizzare dati effettivi. Sia RAID1 che RAID5 possono tollerare
fino al fallimento di 1 disco in quanto utilizzano 1 bit di parita'. Tuttavia
RAID5 utilizza bit di parita' per riparare un eventuale strip di dati perso,
mentre RAID1 funziona duplicando ogni strip su piu' dischi. In questo modo
RAID5 lascia molto piu' spazio per memorizzare dati, mentre con RAID1 si ha
a disposizione sempre e comunque la meta' dello spazio fisicamente disponibile.
FORSE: Con RAID1 tuttavia, avendo i dati duplicati in tutto il pool di dischi
e' statisticamente piu' probabile che la rottura di due dischi non provochi la
perdita di alcun dato, mentre con RAID5 la rottura di piu' di un disco portera'
sicuramente a una qualche quantita' di dati distrutti.

55. Perché è difficile revolacre una autorizzazione fornita tramite una capability?

56. perché l'invenzione degli interrupt ha reso i sistemi operativi più efficienti?

57. ha senso utilizzare RAID 5 con due dischi?

58. in quali casi entra in funzione il paginatore in un sistema di memoria virtuale e quando viene richiamato l'algoritmo
di rimpiazzamento?

59. quali sono i vantaggi e quali gli svantaggi dell'utilizzo di librerie dinamiche?

60.  Perché una system call non può essere implementata come una normale chiamata di funzione ad un indirizzo del
kernel?

61.  Il calcolo del working set dipende dall'algoritmo di rimpiazzamento utilizzato? Perché?

62. Discutere la scelta di usare un file system FAT per una partizione contenente file soggetti a frequenti aggiornamenti
e variazione di dimensione. E' una scelta appropriata o no? perché?

63. Quando viene richiamato l'algoritmo del Banchiere e cosa succede se il risultato dell'algoritmo mostra che lo stato
non è safe?

64. Dati 4 dischi da 1GiB, si possono memorizzare più dati usando una organizzazione RAID10 o RAID5? Perché?

65. Dimostrare che se un algoritmo di rimpiazzamento è a stack allora non può soffrire della anomalia di Belady

66. Quali sono le differenze fra un device driver di una unità con funzionalità di DMA e quello di una unità senza DMA?

67. Come vengono memorizzati i link simbolici in un filesystem?

68.  Esistono partizioni del disco che vengono usate senza creare su di esse strutture di file system? perché?

69.  Un sistema operativo a microkernel è più flessibile, più affidabile ma meno efficiente di un kernel monolitico.
Spiegare brevemente il motivo delle tre affermazioni.

70.  Come vengono memorizzati i link fisici in un filesystem?

71. Quando un sistema è in trashing il carico della CPU (o delle CPU) è alto o basso, perché?

72. il valore della "finestra" del working set dipende dall'algoritmo di rimpiazzamento utilizzato? Perché ?

73. la metodologia RAID protegge dall'esecuzione di programmi errati che rovinano i dati? Perché?
74.  Qual è il numero di link indicati nell'i-node di una directory di un File System UNIX (bffs, ext2, ...)? Perché?
75. I sorgenti del sistema operativo Linux possono essere scaricati e il kernel può essere ricompilato. In quali casi
pensate sia necessario compilare un kernel specifico?
